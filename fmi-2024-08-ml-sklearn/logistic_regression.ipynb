{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Import data analysis modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import visualization modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "plt.ion() # inline matplotlib graphics\n",
    "# pd.options.plotting.backend = 'plotly'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Use pandas to read in csv file of the titanic dataset\n",
    "train = pd.read_csv('data/train.csv')\n",
    "# test = pd.read_csv('data/test.csv')\n",
    "train.head(20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "train.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Use the .isnull() method to locate missing data\n",
    "missing_values = train.isnull()\n",
    "\n",
    "# Use seaborn to conduct heatmap to identify missing data\n",
    "# data -> argument refers to the data to creat heatmap\n",
    "# yticklabels -> argument avoids plotting the column names\n",
    "# cbar -> argument identifies if a colorbar is required or not\n",
    "# cmap -> argument identifies the color of the heatmap\n",
    "sns.heatmap(data = missing_values, yticklabels=False, cbar=False, cmap='viridis')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Survivors ratio\n",
    "sns.countplot(x='Survived', data=train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Use the countplot() method to identify ratio of who survived vs. not with interest in Passenger class\n",
    "# x -> argument referes to column of interest\n",
    "# data -> argument refers to dataset\n",
    "# hue -> allows another level to subdivide data\n",
    "# palette -> argument refers to plot color\n",
    "sns.countplot(x='Survived', data=train, hue='Pclass')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Identify outliers\n",
    "# train.plot(kind=\"box\")\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.boxplot(x='Pclass', y='Age', data=train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Create function to impute the age value if it is null\n",
    "def impute_age(cols):\n",
    "    Age = cols[0]\n",
    "    Pclass = cols[1]\n",
    "\n",
    "    if pd.isnull(Age):\n",
    "\n",
    "        if Pclass == 1:\n",
    "            return 37\n",
    "        elif Pclass == 2:\n",
    "            return 29\n",
    "        else:\n",
    "            return 24\n",
    "    else:\n",
    "        return Age\n",
    "# Apply function to impute the age for missing values\n",
    "# The age column is at position 0\n",
    "# The pclass column is at position 1\n",
    "# axis -> argument refers to columns instead of rows to apply the impute_age function\n",
    "train['Age'] = train[['Age', 'Pclass']].apply(impute_age, axis=1)\n",
    "# test['Age'] = test[['Age', 'Pclass']].apply(impute_age, axis=1)\n",
    "sns.heatmap(data = train.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Remove column 'Cabin' from dataframe, because it contains too many null values\n",
    "train.drop(columns='Cabin', inplace=True)\n",
    "# Remove lines containing null values\n",
    "train.dropna(inplace=True)\n",
    "train.head(20)\n",
    "sns.heatmap(data = train.isnull(), yticklabels=False, cbar=False, cmap='viridis').set_title(\"Train Set\")\n",
    "\n",
    "# # Remove column 'Cabin' from dataframe, because it contains too many null values\n",
    "# test.drop(columns='Cabin', inplace=True)\n",
    "# # Remove lines containing null values\n",
    "# test.dropna(inplace=True)\n",
    "# sns.heatmap(data = test.isnull(), yticklabels=False, cbar=False, cmap='viridis').set_title(\"Test Set\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "print(train['Sex'].unique())\n",
    "print(train['Embarked'].unique())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Use the .get_dummies() method to convert categorical data into dummy values\n",
    "# train['Sex'] refers to the column we want to convert\n",
    "# drop_first -> argument avoids the multicollinearity problem, which can undermines\n",
    "# the statistical significance of an independent variable.\n",
    "sex = pd.get_dummies(train['Sex'], drop_first=True)\n",
    "# sex_test = pd.get_dummies(test['Sex'], drop_first=True)\n",
    "embark = pd.get_dummies(train['Embarked'], drop_first=True)\n",
    "# embark_test = pd.get_dummies(test['Embarked'], drop_first=True)\n",
    "# Use  .concat() method to merge the series data into one dataframe\n",
    "train = pd.concat([train, sex, embark], axis=1)\n",
    "# test = pd.concat([test, sex_test, embark_test], axis=1)\n",
    "train.head(20)\n",
    "# test.head(20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Drop columns with categorical data\n",
    "train.drop(['Sex','Embarked','Ticket','Name','PassengerId'], axis=1, inplace=True)\n",
    "train.head(20)\n",
    "# test.drop(['Sex','Embarked','Ticket','Name','PassengerId'], axis=1, inplace=True)\n",
    "# test.head(20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Split data into 'x' features and 'y' target label sets (if survived)\n",
    "x = train[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'male', 'Q', 'S']]\n",
    "y = train['Survived']\n",
    "# x_test = test[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'male', 'Q', 'S']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Create instance of LogisticRegression and fit the model using the training data\n",
    "logmodel = LogisticRegression(max_iter = 1000)\n",
    "logmodel.fit(x_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "y_predict = logmodel.predict(x_test)\n",
    "x_test_series = x_test.iloc[:,0]\n",
    "predict = pd.concat([x_test, pd.DataFrame({'Y Predicted': y_predict, 'Y Real': y_test})], axis=1)\n",
    "predict.head(50)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Print evaluation statistics\n",
    "print(classification_report(y_test, y_predict))\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
